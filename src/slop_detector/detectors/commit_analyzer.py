"""
Git commit history analysis for AI detection.

Analyzes commit patterns, messages, and authorship for signs of AI assistance.
"""

import re
from collections import Counter
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional

from ..models import CommitAnalysis, DetectionSignal
from .definitive_detector import DefinitiveDetector


@dataclass
class CommitConfig:
    """Configuration for commit analysis."""
    # Time thresholds
    bulk_commit_window_hours: int = 1
    bulk_commit_threshold: int = 10

    # Message analysis
    min_message_length: int = 10


class CommitAnalyzer:
    """Analyze Git commit history for AI patterns."""

    def __init__(self, config: Optional[CommitConfig] = None):
        self.config = config or CommitConfig()
        self.definitive_detector = DefinitiveDetector()

    def analyze_commits(self, commits: list[dict]) -> tuple[list[CommitAnalysis], list[DetectionSignal]]:
        """
        Analyze commit history for AI patterns.

        Returns:
            Tuple of (individual commit analyses, overall signals)
        """
        commit_analyses = []
        overall_signals = []

        if not commits:
            return commit_analyses, overall_signals

        # FIRST: Check for definitive AI markers in commits
        definitive_signals, definitive_stats = self.definitive_detector.analyze_commits(commits)
        overall_signals.extend(definitive_signals)

        # Analyze individual commits
        for commit in commits:
            analysis = self._analyze_single_commit(commit)
            commit_analyses.append(analysis)

        # Analyze patterns across commits
        overall_signals.extend(self._analyze_bulk_commits(commits))
        overall_signals.extend(self._analyze_message_patterns(commits))
        overall_signals.extend(self._analyze_timing_patterns(commits))
        overall_signals.extend(self._analyze_author_patterns(commits))

        # Add summary of definitive findings
        if definitive_stats["ai_commits"] > 0:
            overall_signals.append(DetectionSignal(
                name="DEFINITIVE: AI-attributed commits found",
                score=0.95,
                weight=0.98,  # Extremely high weight
                description=f"{definitive_stats['ai_commits']} commits have explicit AI attribution",
                evidence=list(definitive_stats["ai_authors"])[:5]
            ))

        return commit_analyses, overall_signals

    def _analyze_single_commit(self, commit: dict) -> CommitAnalysis:
        """Analyze a single commit."""
        signals = []
        message = commit.get("message", "")

        # Check for AI-generated commit message patterns
        signals.extend(self._check_message_for_ai(message))

        # Calculate overall probability
        if signals:
            weighted_sum = sum(s.score * s.weight for s in signals)
            total_weight = sum(s.weight for s in signals)
            ai_probability = weighted_sum / total_weight if total_weight > 0 else 0.0
        else:
            ai_probability = 0.0

        return CommitAnalysis(
            sha=commit.get("sha", ""),
            message=message[:100],
            ai_probability=ai_probability,
            signals=signals,
            files_changed=commit.get("files_changed", 0)
        )

    def _check_message_for_ai(self, message: str) -> list[DetectionSignal]:
        """Check commit message for AI patterns."""
        signals = []
        message_lower = message.lower()

        # AI-typical commit message patterns
        ai_patterns = [
            # Overly descriptive messages
            (r"^(?:feat|fix|docs|style|refactor|test|chore)\([^)]+\):\s+.{50,}$",
             "Conventional commit with long description", 0.3),

            # AI explanatory style
            (r"this commit (?:adds|updates|fixes|removes|implements)\b",
             "AI commit explanation style", 0.6),

            # AI politeness in commits (unusual)
            (r"(?:please|kindly|hope|help)\b",
             "Polite language in commit", 0.5),

            # Generated by AI markers
            (r"(?:generated|created|written) (?:by|with|using) (?:ai|gpt|copilot|claude|chatgpt)\b",
             "Explicit AI attribution", 0.95),

            # Co-authored-by AI
            (r"co-authored-by:.*(?:copilot|ai|bot|gpt)\b",
             "AI co-author tag", 0.9),

            # Emoji patterns (AI loves emojis in commits)
            (r"[\U0001F300-\U0001F9FF].*[\U0001F300-\U0001F9FF]",
             "Multiple emojis", 0.4),

            # Very structured format
            (r"^[\u2728\U0001F680\U0001F4DD\U0001F41B\U0001F527]\s+[A-Z]",
             "Emoji prefix pattern", 0.4),

            # Overly detailed for simple changes
            (r"(?:implement|add|create|update).*(?:functionality|feature|module|component).*(?:that|which|to)",
             "Verbose description", 0.4),
        ]

        for pattern, name, weight in ai_patterns:
            if re.search(pattern, message_lower, re.IGNORECASE):
                signals.append(DetectionSignal(
                    name=name,
                    score=0.6,
                    weight=weight,
                    description=f"Commit message matches '{name}' pattern",
                    evidence=[message[:50]]
                ))

        # Check message length (AI tends toward specific ranges)
        words = message.split()
        if len(words) > 50:
            signals.append(DetectionSignal(
                name="Very long commit message",
                score=0.5,
                weight=0.3,
                description=f"Commit message has {len(words)} words (unusually detailed)",
                evidence=[]
            ))

        return signals

    def _analyze_bulk_commits(self, commits: list[dict]) -> list[DetectionSignal]:
        """Analyze for bulk commit patterns."""
        signals = []

        if len(commits) < self.config.bulk_commit_threshold:
            return signals

        # Group commits by time window
        commits_with_time = [
            c for c in commits
            if isinstance(c.get("date"), datetime)
        ]

        if not commits_with_time:
            return signals

        # Sort by date
        commits_with_time.sort(key=lambda c: c["date"])

        # Find bursts of commits
        window = timedelta(hours=self.config.bulk_commit_window_hours)
        burst_counts = []
        i = 0

        while i < len(commits_with_time):
            start_time = commits_with_time[i]["date"]
            count = 1
            j = i + 1

            while j < len(commits_with_time):
                if commits_with_time[j]["date"] - start_time <= window:
                    count += 1
                    j += 1
                else:
                    break

            if count >= 5:  # Significant burst
                burst_counts.append(count)

            i = j if j > i + 1 else i + 1

        if burst_counts:
            max_burst = max(burst_counts)
            if max_burst >= self.config.bulk_commit_threshold:
                signals.append(DetectionSignal(
                    name="Bulk commit burst",
                    score=min(0.7, 0.3 + max_burst * 0.03),
                    weight=0.5,
                    description=f"Found burst of {max_burst} commits in {self.config.bulk_commit_window_hours}h window",
                    evidence=[f"Burst sizes: {burst_counts[:5]}"]
                ))

        return signals

    def _analyze_message_patterns(self, commits: list[dict]) -> list[DetectionSignal]:
        """Analyze patterns across commit messages."""
        signals = []

        messages = [c.get("message", "") for c in commits if c.get("message")]
        if len(messages) < 5:
            return signals

        # Check for uniform message style
        conventional_count = sum(
            1 for m in messages
            if re.match(r"^(?:feat|fix|docs|style|refactor|test|chore|ci|build|perf)\(?", m.lower())
        )

        if conventional_count / len(messages) > 0.9:
            signals.append(DetectionSignal(
                name="Uniform conventional commits",
                score=0.4,
                weight=0.3,
                description=f"{conventional_count}/{len(messages)} commits use conventional format",
                evidence=["High consistency may indicate tooling or AI"]
            ))

        # Check for repetitive patterns
        first_words = [m.split()[0].lower() if m.split() else "" for m in messages]
        from collections import Counter
        word_counts = Counter(first_words)
        most_common = word_counts.most_common(1)

        if most_common and most_common[0][1] / len(messages) > 0.5:
            signals.append(DetectionSignal(
                name="Repetitive commit prefixes",
                score=0.45,
                weight=0.35,
                description=f"'{most_common[0][0]}' starts {most_common[0][1]}/{len(messages)} commits",
                evidence=[]
            ))

        return signals

    def _analyze_timing_patterns(self, commits: list[dict]) -> list[DetectionSignal]:
        """Analyze commit timing patterns."""
        signals = []

        commits_with_time = [
            c for c in commits
            if isinstance(c.get("date"), datetime)
        ]

        if len(commits_with_time) < 10:
            return signals

        # Analyze time-of-day distribution
        hours = [c["date"].hour for c in commits_with_time]

        # Check for unusual patterns (e.g., all commits at same time)
        from collections import Counter
        hour_counts = Counter(hours)

        # If commits are too concentrated in specific hours
        most_common_hour = hour_counts.most_common(1)[0]
        if most_common_hour[1] / len(hours) > 0.4:
            signals.append(DetectionSignal(
                name="Time-concentrated commits",
                score=0.35,
                weight=0.25,
                description=f"{most_common_hour[1]}/{len(hours)} commits at {most_common_hour[0]}:00",
                evidence=["May indicate automated or batched work"]
            ))

        return signals

    def _analyze_author_patterns(self, commits: list[dict]) -> list[DetectionSignal]:
        """Analyze author patterns."""
        signals = []

        # AI-specific author patterns (high confidence)
        ai_author_patterns = [
            (r"^claude$", "Claude AI author", 0.95),
            (r"claude\s*(opus|sonnet|haiku)", "Claude model author", 0.98),
            (r"copilot", "Copilot author", 0.90),
            (r"^gpt", "GPT author", 0.90),
            (r"chatgpt", "ChatGPT author", 0.95),
            (r"anthropic", "Anthropic author", 0.95),
            (r"openai", "OpenAI author", 0.90),
            (r"^cursor$", "Cursor AI author", 0.85),
            (r"^aider$", "Aider AI author", 0.90),
            (r"codeium", "Codeium author", 0.85),
        ]

        # Bot patterns (lower confidence - not necessarily AI content)
        bot_patterns = [
            r"bot\b",
            r"dependabot",
            r"renovate",
            r"github-actions",
            r"ci[-_]?bot",
            r"auto[-_]?commit",
        ]

        authors = set(c.get("author", "").lower() for c in commits)
        author_emails = set(c.get("author_email", "").lower() for c in commits)

        # Check for AI authors (high confidence)
        for author in authors:
            for pattern, name, score in ai_author_patterns:
                if re.search(pattern, author, re.IGNORECASE):
                    signals.append(DetectionSignal(
                        name=f"DEFINITIVE: {name}",
                        score=score,
                        weight=0.95,
                        description=f"Found AI author: {author}",
                        evidence=[author]
                    ))

        # Check emails for AI patterns
        for email in author_emails:
            if "anthropic.com" in email:
                signals.append(DetectionSignal(
                    name="DEFINITIVE: Anthropic email author",
                    score=0.98,
                    weight=0.95,
                    description=f"Found Anthropic email: {email}",
                    evidence=[email]
                ))
            elif "copilot@github" in email:
                signals.append(DetectionSignal(
                    name="DEFINITIVE: GitHub Copilot email",
                    score=0.98,
                    weight=0.95,
                    description=f"Found Copilot email: {email}",
                    evidence=[email]
                ))

        # Check for bot authors (lower confidence)
        bot_authors = [
            a for a in authors
            if any(re.search(p, a) for p in bot_patterns)
            and not any(re.search(p, a, re.IGNORECASE) for p, _, _ in ai_author_patterns)
        ]

        if bot_authors:
            signals.append(DetectionSignal(
                name="Bot authors detected",
                score=0.3,
                weight=0.2,
                description=f"Found bot-like author names: {', '.join(bot_authors[:3])}",
                evidence=bot_authors[:3]
            ))

        return signals
